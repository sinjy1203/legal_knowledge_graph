from tqdm.auto import tqdm
import json
from uuid import uuid4
from neo4j import GraphDatabase


NODE_TYPES = ["Corpus", "Article", "Section", "Chunk"]
RELATIONSHIP_TYPES = ["CHILD", "NEXT", "PREV"]


class Neo4jConnection:
    def __init__(self, uri, user, password, embedding_model):
        self.driver = GraphDatabase.driver(uri, auth=(user, password))
        self.embedding_model = embedding_model
       
    def close(self):
        self.driver.close()
    
    def clear_database(self):
        with self.driver.session() as session:
            session.run("MATCH (n) DETACH DELETE n")
            
            # ë¬¸ì„œ ë…¸ë“œ ì œì•½ì¡°ê±´ ì‚­ì œ
            for node_type in NODE_TYPES:
                session.run(f"DROP CONSTRAINT {node_type.lower()}_id_unique IF EXISTS")
            
            for node_type in NODE_TYPES:
                if node_type == "Corpus":
                    continue
                session.run(f"DROP INDEX {node_type.lower()}_vector_index IF EXISTS")
    
    def batch_embed(self, texts, batch_size=4):
        embedding_vectors = []
        for i in tqdm(range(0, len(texts), batch_size), desc=f"ì„ë² ë”© ë²¡í„° ìƒì„± ì¤‘..."):
            batch = texts[i:i + batch_size]
            embedding_vectors += self.embedding_model.embed_documents(batch)
        
        return embedding_vectors
    
    def setup_vector_indexes(self):
        """ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        print("ğŸ”§ ë¬¸ì„œ ë²¡í„° ì¸ë±ìŠ¤ ì„¤ì • ì¤‘...")
        with self.driver.session() as session:
            # ë¬¸ì„œ ë…¸ë“œ íƒ€ì…ì— ëŒ€í•œ ë²¡í„° ì¸ë±ìŠ¤
            node_types = NODE_TYPES
            
            for node_type in NODE_TYPES:
                if node_type == "Corpus":
                    continue
                session.run(f"""
                CREATE VECTOR INDEX {node_type.lower()}_vector_index IF NOT EXISTS
                FOR (n:{node_type})
                ON (n.vector)
                OPTIONS {{
                    indexConfig: {{
                        `vector.dimensions`: 3072,
                        `vector.similarity_function`: "cosine"
                    }}
                }}
                """)
                print(f"âœ… {node_type} ë…¸ë“œ ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
            
        # print("âœ… ë¬¸ì„œ, ì—”í‹°í‹° ë° ê´€ê³„ ë²¡í„° ì¸ë±ìŠ¤ ì„¤ì • ì™„ë£Œ")
    
    def setup_constraints(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì œì•½ ì¡°ê±´ ì„¤ì •"""
        with self.driver.session() as session:
            # ë¬¸ì„œ ë…¸ë“œ ì œì•½ì¡°ê±´ ìƒì„±
            node_types = NODE_TYPES
            for node_type in node_types:
                session.run(f"""
                    CREATE CONSTRAINT {node_type.lower()}_id_unique IF NOT EXISTS
                    FOR (n:{node_type})
                    REQUIRE n.id IS UNIQUE
                """)
                print(f"âœ… {node_type} ID ì œì•½ì¡°ê±´ ìƒì„± ì™„ë£Œ")

    def create_nodes_and_relationships(self, documents):
        with self.driver.session() as session:
            # ì„ë² ë”© ëŒ€ìƒ ìˆ˜ì§‘ìš© ë²„í¼
            node_ids_for_embedding = []
            texts_for_embedding = []

            def ensure_corpus(file_path: str, table_of_contents: dict | None = None):
                corpus_id = str(uuid4())
                corpus_name = file_path.split("/")[-1] if file_path else ""
                toc_str = json.dumps(table_of_contents or {}, ensure_ascii=False)
                session.run(
                    """
                    MERGE (co:Corpus {id: $corpus_id})
                    SET co.name = $corpus_name,
                        co.file_path = $file_path,
                        co.table_of_contents = $table_of_contents
                    """,
                    {
                        "corpus_id": corpus_id,
                        "corpus_name": corpus_name,
                        "file_path": file_path,
                        "table_of_contents": toc_str,
                    },
                )
                return corpus_id

            def create_chunks_recursive(parent_label: str, parent_id: str, chunk_obj, order_idx: int = 0, file_path: str = ""):
                chunk_id = str(uuid4())
                # Chunk ê°ì²´ ì²˜ë¦¬ (dictëŠ” ë“¤ì–´ì˜¤ì§€ ì•ŠìŒ)
                span_value = list(getattr(chunk_obj, "span", (0, 0)))
                content_value = getattr(chunk_obj, "content", "")
                summary_value = getattr(chunk_obj, "summary", "")
                name_value = getattr(chunk_obj, "name", "")
                session.run(
                    """
                    MERGE (c:Chunk {id: $chunk_id})
                    ON CREATE SET c.span = $span,
                                  c.content = $content,
                                  c.summary = $summary,
                                  c.order = $order,
                                  c.name = $name,
                                  c.file_path = $file_path
                    """,
                    {
                        "chunk_id": chunk_id,
                        "span": span_value,
                        "content": content_value,
                        "summary": summary_value,
                        "order": order_idx,
                        "name": name_value,
                        "file_path": file_path,
                    },
                )
                session.run(
                    f"""
                    MATCH (p:{parent_label} {{id: $parent_id}}), (c:Chunk {{id: $chunk_id}})
                    MERGE (p)-[:CHILD]->(c)
                    """,
                    {"parent_id": parent_id, "chunk_id": chunk_id},
                )
                # ìì‹ ì¬ê·€ ë° NEXT/PREV ì—°ê²°
                prev_child_id = None
                for child_idx, child in enumerate(getattr(chunk_obj, "children", []) or []):
                    child_chunk_id = create_chunks_recursive("Chunk", chunk_id, child, child_idx, file_path)
                    if prev_child_id is not None:
                        session.run(
                            """
                            MATCH (p:Chunk {id: $prev}), (c:Chunk {id: $cur})
                            MERGE (p)-[:NEXT]->(c)
                            MERGE (c)-[:PREV]->(p)
                            """,
                            {"prev": prev_child_id, "cur": child_chunk_id},
                        )
                    prev_child_id = child_chunk_id

                # ì„ë² ë”© ëŒ€ìƒ í…ìŠ¤íŠ¸ ì„ íƒ: summaryê°€ ë¹„ì—ˆìœ¼ë©´ content ì‚¬ìš©
                text_for_vec = summary_value.strip() if summary_value and summary_value.strip() else content_value
                if text_for_vec.strip():
                    node_ids_for_embedding.append(("Chunk", chunk_id))
                    texts_for_embedding.append(text_for_vec)
                return chunk_id

            for doc in documents:
                file_path = getattr(doc, "file_path", "")
                toc = getattr(doc, "table_of_contents", {}) or {}
                corpus_id = ensure_corpus(file_path, toc)
                # ë¬¸ì„œ ë£¨íŠ¸ëŠ” Articleë¡œ ê°„ì£¼í•˜ì§€ ì•Šê³ , Corpus -> Chunk íŠ¸ë¦¬ë¡œ ì ì¬
                prev_top_id = None
                # dict íŠ¸ë¦¬ë¥¼ ìˆœíšŒ
                top_children = getattr(doc, "children", {}) or {}
                prev_top_id = None
                for idx, top_chunk in enumerate(list(top_children.values())):
                    top_id = create_chunks_recursive("Corpus", corpus_id, top_chunk, idx, file_path)
                    if prev_top_id is not None:
                        session.run(
                            """
                            MATCH (p:Chunk {id: $prev}), (c:Chunk {id: $cur})
                            MERGE (p)-[:NEXT]->(c)
                            MERGE (c)-[:PREV]->(p)
                            """,
                            {"prev": prev_top_id, "cur": top_id},
                        )
                    prev_top_id = top_id

                # ë¬¸ì„œ ìš”ì•½ë„ ì €ì¥ ë° ë²¡í„°í™” ëŒ€ìƒ
                doc_summary = getattr(doc, "summary", "")
                doc_content = getattr(doc, "content", "")
                text_for_vec = doc_summary.strip() if doc_summary and doc_summary.strip() else doc_content
                session.run(
                    """
                    MERGE (doc:Corpus {id: $corpus_id})
                    SET doc.summary = $summary,
                        doc.content = $content
                    """,
                    {"corpus_id": corpus_id, "summary": doc_summary, "content": doc_content},
                )
                if text_for_vec.strip():
                    node_ids_for_embedding.append(("Corpus", corpus_id))
                    texts_for_embedding.append(text_for_vec)

            # ì„ë² ë”© ìƒì„± í›„ ê° ë…¸ë“œì— ì €ì¥
            if texts_for_embedding:
                vectors = self.batch_embed(texts_for_embedding)
                for (label, node_id), vec in zip(node_ids_for_embedding, vectors):
                    session.run(
                        f"""
                        MATCH (n:{label} {{id: $id}})
                        SET n.vector = $vector
                        """,
                        {"id": node_id, "vector": vec},
                    )
